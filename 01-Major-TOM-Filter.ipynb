{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d62a92-c115-4364-90f4-b638c347e493",
   "metadata": {},
   "source": [
    "# Major-TOM Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f518055e-c955-43c6-a5e1-0c05bc657b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "SOURCE_DATASET = 'Major-TOM/Core-S2L2A' # Identify HF Dataset\n",
    "DATASET_DIR = Path('./data/Major-TOM/')\n",
    "DATASET_DIR.mkdir(exist_ok=True, parents=True)\n",
    "ACCESS_URL = 'https://huggingface.co/datasets/{}/resolve/main/metadata.parquet?download=true'.format(SOURCE_DATASET)\n",
    "LOCAL_URL = DATASET_DIR / '{}.parquet'.format(ACCESS_URL.split('.parquet')[0].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfceaf2e-b877-48a0-a520-450dd73cb57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "LOCAL_URL, RESPONSE = urllib.request.urlretrieve(ACCESS_URL, LOCAL_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76d787c-4c4d-43da-bc00-adf1067edf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_cell</th>\n",
       "      <th>grid_row_u</th>\n",
       "      <th>grid_col_r</th>\n",
       "      <th>product_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>nodata</th>\n",
       "      <th>centre_lat</th>\n",
       "      <th>centre_lon</th>\n",
       "      <th>crs</th>\n",
       "      <th>parquet_url</th>\n",
       "      <th>parquet_row</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>922D_249L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-249</td>\n",
       "      <td>S2A_MSIL2A_20230119T161811_N0509_R111_T01CDJ_2...</td>\n",
       "      <td>2023-01-19 16:18:11</td>\n",
       "      <td>18.941737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.770666</td>\n",
       "      <td>-178.200331</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-178.200 -82.771)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>922D_245L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-245</td>\n",
       "      <td>S2B_MSIL2A_20181219T162339_N9999_R011_T01CEJ_2...</td>\n",
       "      <td>2018-12-19 16:23:39</td>\n",
       "      <td>22.742201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.768451</td>\n",
       "      <td>-175.349546</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-175.350 -82.768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>922D_244L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-244</td>\n",
       "      <td>S2A_MSIL2A_20200119T155811_N9999_R025_T01CEJ_2...</td>\n",
       "      <td>2020-01-19 15:58:11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.767914</td>\n",
       "      <td>-174.636985</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-174.637 -82.768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>922D_243L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-243</td>\n",
       "      <td>S2A_MSIL2A_20210103T155811_N9999_R025_T01CEJ_2...</td>\n",
       "      <td>2021-01-03 15:58:11</td>\n",
       "      <td>3.769691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.767385</td>\n",
       "      <td>-173.924477</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-173.924 -82.767)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>922D_242L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-242</td>\n",
       "      <td>S2B_MSIL2A_20181220T155319_N9999_R025_T01CEJ_2...</td>\n",
       "      <td>2018-12-20 15:53:19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.766864</td>\n",
       "      <td>-173.212021</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>4</td>\n",
       "      <td>POINT (-173.212 -82.767)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_cell  grid_row_u  grid_col_r  \\\n",
       "0  922D_249L        -922        -249   \n",
       "1  922D_245L        -922        -245   \n",
       "2  922D_244L        -922        -244   \n",
       "3  922D_243L        -922        -243   \n",
       "4  922D_242L        -922        -242   \n",
       "\n",
       "                                          product_id           timestamp  \\\n",
       "0  S2A_MSIL2A_20230119T161811_N0509_R111_T01CDJ_2... 2023-01-19 16:18:11   \n",
       "1  S2B_MSIL2A_20181219T162339_N9999_R011_T01CEJ_2... 2018-12-19 16:23:39   \n",
       "2  S2A_MSIL2A_20200119T155811_N9999_R025_T01CEJ_2... 2020-01-19 15:58:11   \n",
       "3  S2A_MSIL2A_20210103T155811_N9999_R025_T01CEJ_2... 2021-01-03 15:58:11   \n",
       "4  S2B_MSIL2A_20181220T155319_N9999_R025_T01CEJ_2... 2018-12-20 15:53:19   \n",
       "\n",
       "   cloud_cover  nodata  centre_lat  centre_lon         crs  \\\n",
       "0    18.941737     0.0  -82.770666 -178.200331  EPSG:32701   \n",
       "1    22.742201     0.0  -82.768451 -175.349546  EPSG:32701   \n",
       "2     0.000000     0.0  -82.767914 -174.636985  EPSG:32701   \n",
       "3     3.769691     0.0  -82.767385 -173.924477  EPSG:32701   \n",
       "4     0.000000     0.0  -82.766864 -173.212021  EPSG:32701   \n",
       "\n",
       "                                         parquet_url  parquet_row  \\\n",
       "0  https://huggingface.co/datasets/Major-TOM/Core...            0   \n",
       "1  https://huggingface.co/datasets/Major-TOM/Core...            1   \n",
       "2  https://huggingface.co/datasets/Major-TOM/Core...            2   \n",
       "3  https://huggingface.co/datasets/Major-TOM/Core...            3   \n",
       "4  https://huggingface.co/datasets/Major-TOM/Core...            4   \n",
       "\n",
       "                   geometry  \n",
       "0  POINT (-178.200 -82.771)  \n",
       "1  POINT (-175.350 -82.768)  \n",
       "2  POINT (-174.637 -82.768)  \n",
       "3  POINT (-173.924 -82.767)  \n",
       "4  POINT (-173.212 -82.767)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "df = pq.read_table(LOCAL_URL).to_pandas()\n",
    "df['timestamp'] = pd.to_datetime(df.timestamp)\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.centre_lon, df.centre_lat), crs=df.crs.iloc[0]\n",
    ")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c3a158-1bbf-4554-a235-5acc83bd78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metadata(df,\n",
    "                    region=None,\n",
    "                    daterange=None,\n",
    "                    cloud_cover=(0,100),\n",
    "                    nodata=(0, 1.0)\n",
    "                   ):\n",
    "    \"\"\"Filters the Major-TOM dataframe based on several parameters\n",
    "\n",
    "    Args:\n",
    "        df (geopandas dataframe): Parent dataframe\n",
    "        region (shapely geometry object) : Region of interest\n",
    "        daterange (tuple) : Inclusive range of dates (example format: '2020-01-01')\n",
    "        cloud_cover (tuple) : Inclusive percentage range (0-100) of cloud cover\n",
    "        nodata (tuple) : Inclusive fraction (0.0-1.0) of no data allowed in a sample\n",
    "\n",
    "    Returns:\n",
    "        df: a filtered dataframe\n",
    "    \"\"\"\n",
    "    # temporal filtering\n",
    "    if daterange is not None:\n",
    "        assert (isinstance(daterange, list) or isinstance(daterange, tuple)) and len(daterange)==2\n",
    "        df = df[df.timestamp >= daterange[0]]\n",
    "        df = df[df.timestamp <= daterange[1]]\n",
    "    \n",
    "    # spatial filtering\n",
    "    if region is not None:\n",
    "        idxs = df.sindex.query(region)\n",
    "        df = df.take(idxs)\n",
    "    # cloud filtering\n",
    "    if cloud_cover is not None:\n",
    "        df = df[df.cloud_cover >= cloud_cover[0]]\n",
    "        df = df[df.cloud_cover <= cloud_cover[1]]\n",
    "\n",
    "    # spatial filtering\n",
    "    if nodata is not None:\n",
    "        df = df[df.nodata >= nodata[0]]\n",
    "        df = df[df.nodata <= nodata[1]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a0fcff-7df1-466d-9109-b4a64f7daf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "\n",
    "# Example bounding boxes used for filtering\n",
    "switzerland = box(5.9559111595,45.8179931641,10.4920501709,47.808380127)\n",
    "gabon = box(8.1283659854,-4.9213919841,15.1618722208,2.7923006325)\n",
    "napoli = box(14.091710578,40.7915558593,14.3723765416,40.9819258062)\n",
    "pacific = box(-153.3922893485,39.6170415622,-152.0423077748,40.7090892316) # a remote patch over pacific - no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb50b0db-249a-42e7-ac2f-b18ca682a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter_metadata(gdf,\n",
    "                              cloud_cover = (0,10),\n",
    "                              region=napoli,\n",
    "                              daterange=('2020-01-01', '2025-01-01'),\n",
    "                              nodata=(0.0,0.0)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72f3406-c23d-4f54-b589-45b6511cb9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mczerkawski/mambaforge/envs/miko-torch/lib/python3.8/site-packages/fsspec/parquet.py:225: UserWarning: Not enough data was used to sample the parquet footer. Try setting footer_sample_size >= 1031336.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fsspec.parquet import open_parquet_file\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from rasterio.io import MemoryFile\n",
    "\n",
    "def read_row(row, columns=[\"thumbnail\"]):\n",
    "    \"\"\"Reads a row from a Major-TOM dataframe\n",
    "\n",
    "    Args:\n",
    "        row (row from geopandas dataframe): The row of metadata\n",
    "        columns (list): columns to be read from the file\n",
    "\n",
    "    Returns:\n",
    "        data (dict): dictionary with returned data from requested columns\n",
    "    \"\"\"\n",
    "    with open_parquet_file(row.parquet_url,columns = columns) as f:\n",
    "        with pq.ParquetFile(f) as pf:\n",
    "            row_group = pf.read_row_group(row.parquet_row, columns=columns)\n",
    "\n",
    "    if columns == [\"thumbnail\"]:\n",
    "        stream = BytesIO(row_group['thumbnail'][0].as_py())\n",
    "        return Image.open(stream)\n",
    "    else:\n",
    "        row_output = {}\n",
    "        for col in columns:\n",
    "            bytes = row_group[col][0].as_py()\n",
    "\n",
    "            if col != 'thumbnail':\n",
    "                with MemoryFile(bytes) as mem_f:\n",
    "                    with mem_f.open(driver='GTiff') as f:\n",
    "                        row_output[col] = f.read().squeeze()\n",
    "            else:\n",
    "                stream = BytesIO(bytes)\n",
    "                row_output[col] = Image.open(stream)\n",
    "\n",
    "        return row_output\n",
    "        \n",
    "\n",
    "out = read_row(filtered_df.iloc[0], columns = ['B04', 'thumbnail'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044c465-bc91-4d56-89de-7121970f4271",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5547d11b-28c8-4408-9345-3cca4a024f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_cell</th>\n",
       "      <th>grid_row_u</th>\n",
       "      <th>grid_col_r</th>\n",
       "      <th>product_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>nodata</th>\n",
       "      <th>centre_lat</th>\n",
       "      <th>centre_lon</th>\n",
       "      <th>crs</th>\n",
       "      <th>parquet_url</th>\n",
       "      <th>parquet_row</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593374</th>\n",
       "      <td>454U_120R</td>\n",
       "      <td>454</td>\n",
       "      <td>120</td>\n",
       "      <td>S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...</td>\n",
       "      <td>2022-07-19 09:55:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.823861</td>\n",
       "      <td>14.292709</td>\n",
       "      <td>EPSG:32633</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>455</td>\n",
       "      <td>POINT (14.293 40.824)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595266</th>\n",
       "      <td>455U_120R</td>\n",
       "      <td>455</td>\n",
       "      <td>120</td>\n",
       "      <td>S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...</td>\n",
       "      <td>2022-07-19 09:55:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.913671</td>\n",
       "      <td>14.311585</td>\n",
       "      <td>EPSG:32633</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>347</td>\n",
       "      <td>POINT (14.312 40.914)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595265</th>\n",
       "      <td>455U_119R</td>\n",
       "      <td>455</td>\n",
       "      <td>119</td>\n",
       "      <td>S2A_MSIL2A_20200113T095351_N0500_R079_T33TVF_2...</td>\n",
       "      <td>2020-01-13 09:53:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.913731</td>\n",
       "      <td>14.192730</td>\n",
       "      <td>EPSG:32633</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>346</td>\n",
       "      <td>POINT (14.193 40.914)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_cell  grid_row_u  grid_col_r  \\\n",
       "1593374  454U_120R         454         120   \n",
       "1595266  455U_120R         455         120   \n",
       "1595265  455U_119R         455         119   \n",
       "\n",
       "                                                product_id  \\\n",
       "1593374  S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...   \n",
       "1595266  S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...   \n",
       "1595265  S2A_MSIL2A_20200113T095351_N0500_R079_T33TVF_2...   \n",
       "\n",
       "                  timestamp  cloud_cover  nodata  centre_lat  centre_lon  \\\n",
       "1593374 2022-07-19 09:55:59          0.0     0.0   40.823861   14.292709   \n",
       "1595266 2022-07-19 09:55:59          0.0     0.0   40.913671   14.311585   \n",
       "1595265 2020-01-13 09:53:51          0.0     0.0   40.913731   14.192730   \n",
       "\n",
       "                crs                                        parquet_url  \\\n",
       "1593374  EPSG:32633  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1595266  EPSG:32633  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1595265  EPSG:32633  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "\n",
       "         parquet_row               geometry  \n",
       "1593374          455  POINT (14.293 40.824)  \n",
       "1595266          347  POINT (14.312 40.914)  \n",
       "1595265          346  POINT (14.193 40.914)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "864ccdc6-03ae-48cc-a4a5-3c87409e6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import fsspec\n",
    "from fsspec.parquet import open_parquet_file\n",
    "\n",
    "def filter_download(df, local_dir, source_name, by_row = False, verbose = False, tif_columns=None):\n",
    "    \"\"\"Downloads and unpacks the data of Major-TOM based on a metadata dataframe\n",
    "\n",
    "    Args:\n",
    "        df (geopandas dataframe): Metadata dataframe\n",
    "        local_dir (str or Path) : Path to the where the data is to be stored locally\n",
    "        source_name (str) : Name alias of the resulting dataset\n",
    "        by_row (bool): If True, it will access individual rows of parquet via http - otherwise entire parquets are downloaded temporarily\n",
    "        verbose (bool) : option for potential internal state printing\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(local_dir, str):\n",
    "        local_dir = Path(local_dir)\n",
    "\n",
    "    temp_file = local_dir / 'temp.parquet'\n",
    "\n",
    "    # identify all parquets that need to be downloaded (group them)\n",
    "    urls = df.parquet_url.unique()\n",
    "    print('Starting download of {} parquet files.'.format(len(urls))) if verbose else None\n",
    "\n",
    "    for url in tqdm(urls, desc='Downloading and unpacking...'):\n",
    "        # identify all relevant rows\n",
    "        rows = df[df.parquet_url == url].parquet_row.unique()\n",
    "        \n",
    "        if not by_row: # (downloads entire parquet)        \n",
    "            # download a temporary file\n",
    "            temp_path, http_resp = urllib.request.urlretrieve(url, temp_file)            \n",
    "        else:\n",
    "            f=fsspec.open(url)\n",
    "            temp_path = f.open()\n",
    "            \n",
    "        # populate the bands\n",
    "        with pq.ParquetFile(temp_path) as pf:\n",
    "            for row_idx in rows:\n",
    "                table = pf.read_row_group(row_idx)\n",
    "\n",
    "                product_id = table['product_id'][0].as_py()\n",
    "                grid_cell = table['grid_cell'][0].as_py()\n",
    "                row = grid_cell.split('_')[0]\n",
    "            \n",
    "                dest = local_dir / Path(\"{}/{}/{}/{}\".format(source_name, row, grid_cell, product_id))\n",
    "                dest.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "                columns = [col for col in table.column_names if col[0] == 'B'] + ['cloud_mask'] if tif_columns is None else tif_columns\n",
    "                # tifs\n",
    "                for col in columns:\n",
    "                    with open(dest / \"{}.tif\".format(col), \"wb\") as f:\n",
    "                        # Write bytes to file\n",
    "                        f.write(table[col][0].as_py())\n",
    "\n",
    "                # thumbnail (png)\n",
    "                col = 'thumbnail'\n",
    "                with open(dest / \"{}.png\".format(col), \"wb\") as f:\n",
    "                    # Write bytes to file\n",
    "                    f.write(table[col][0].as_py())\n",
    "        if not by_row:\n",
    "            # remove downloaded file\n",
    "            os.remove(temp_path)\n",
    "        else:\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "335ab665-8238-4f17-ab4b-0bcb1fa38224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb23c9cd8514d3791c4f8118a96c481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading and unpacking...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_download(filtered_df, local_dir='./data/mczerkawski', source_name='L2A', by_row=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c9c0fc63-30ef-48ab-9b2a-ea9bc94441cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88024cc750b041459211e3594703f79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading and unpacking...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_download(filtered_df, local_dir='./data/mczerkawski', source_name='L2A', by_row=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b33084-cc9c-4b4e-acff-e6b68e64ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': grid_cell                                              454U_120R\n",
       " grid_row_u                                                   454\n",
       " grid_col_r                                                   120\n",
       " product_id     S2B_MSIL1C_20220719T095559_N0400_R122_T33TVF_2...\n",
       " timestamp                                    2022-07-19 09:55:59\n",
       " cloud_cover                                                  0.0\n",
       " nodata                                                       0.0\n",
       " centre_lat                                             40.823861\n",
       " centre_lon                                             14.292709\n",
       " crs                                                   EPSG:32633\n",
       " parquet_url    https://huggingface.co/datasets/Major-TOM/Core...\n",
       " parquet_row                                                  455\n",
       " geometry             POINT (14.29270867998482 40.82386055223662)\n",
       " Name: 1593374, dtype: object,\n",
       " 'cloud_mask': array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " 'thumbnail': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1068x1068>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import rasterio as rio\n",
    "\n",
    "class MajorTOM(Dataset):\n",
    "    \"\"\"MajorTOM Dataset (https://huggingface.co/Major-TOM)\n",
    "\n",
    "    Args:\n",
    "        df ((geo)pandas.DataFrame): Metadata dataframe\n",
    "        local_dir (string): Root directory of the local dataset version\n",
    "        tif_bands (list): A list of tif file names to be read\n",
    "        png_bands (list): A list of png file names to be read\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 local_dir = None,\n",
    "                 tif_bands=['B04','B03','B02'],\n",
    "                 png_bands=['thumbnail']\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.local_dir = Path(local_dir) if isinstance(local_dir,str) else local_dir\n",
    "        self.tif_bands = tif_bands if not isinstance(tif_bands,str) else [tif_bands]\n",
    "        self.png_bands = png_bands if not isinstance(png_bands,str) else [png_bands]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        meta = self.df.iloc[idx]\n",
    "\n",
    "        product_id = meta.product_id\n",
    "        grid_cell = meta.grid_cell\n",
    "        row = grid_cell.split('_')[0]\n",
    "    \n",
    "        path = self.local_dir / Path(\"{}/{}/{}\".format(row, grid_cell, product_id))\n",
    "        out_dict = {'meta' : meta}\n",
    "        \n",
    "        for band in self.tif_bands:\n",
    "            with rio.open(path / '{}.tif'.format(band)) as f:\n",
    "                out = f.read()\n",
    "            out_dict[band] = out\n",
    "\n",
    "        for band in self.png_bands:\n",
    "            out_dict[band] = Image.open(path / '{}.png'.format(band))\n",
    "\n",
    "        return out_dict\n",
    "        \n",
    "ds = MajorTOM(filtered_df, './data/mczerkawski/L2A')\n",
    "\n",
    "ds[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miko-torch] *",
   "language": "python",
   "name": "conda-env-miko-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
