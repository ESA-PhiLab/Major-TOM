{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d62a92-c115-4364-90f4-b638c347e493",
   "metadata": {},
   "source": [
    "# Major-TOM Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f518055e-c955-43c6-a5e1-0c05bc657b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "SOURCE_DATASET = 'Major-TOM/Core-S2L2A' # Identify HF Dataset\n",
    "DATASET_DIR = Path('./data/Major-TOM/')\n",
    "DATASET_DIR.mkdir(exist_ok=True, parents=True)\n",
    "ACCESS_URL = 'https://huggingface.co/datasets/{}/resolve/main/metadata.parquet?download=true'.format(SOURCE_DATASET)\n",
    "LOCAL_URL = DATASET_DIR / '{}.parquet'.format(ACCESS_URL.split('.parquet')[0].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfceaf2e-b877-48a0-a520-450dd73cb57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "LOCAL_URL, RESPONSE = urllib.request.urlretrieve(ACCESS_URL, LOCAL_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76d787c-4c4d-43da-bc00-adf1067edf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_cell</th>\n",
       "      <th>grid_row_u</th>\n",
       "      <th>grid_col_r</th>\n",
       "      <th>product_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>nodata</th>\n",
       "      <th>centre_lat</th>\n",
       "      <th>centre_lon</th>\n",
       "      <th>crs</th>\n",
       "      <th>parquet_url</th>\n",
       "      <th>parquet_row</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>922D_249L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-249</td>\n",
       "      <td>S2A_MSIL2A_20230119T161811_N0509_R111_T01CDJ_2...</td>\n",
       "      <td>2023-01-19 16:18:11</td>\n",
       "      <td>18.941737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.770666</td>\n",
       "      <td>-178.200331</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-178.200 -82.771)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>922D_245L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-245</td>\n",
       "      <td>S2B_MSIL2A_20181219T162339_N9999_R011_T01CEJ_2...</td>\n",
       "      <td>2018-12-19 16:23:39</td>\n",
       "      <td>22.742201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.768451</td>\n",
       "      <td>-175.349546</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-175.350 -82.768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>922D_244L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-244</td>\n",
       "      <td>S2A_MSIL2A_20200119T155811_N9999_R025_T01CEJ_2...</td>\n",
       "      <td>2020-01-19 15:58:11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.767914</td>\n",
       "      <td>-174.636985</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-174.637 -82.768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>922D_243L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-243</td>\n",
       "      <td>S2A_MSIL2A_20210103T155811_N9999_R025_T01CEJ_2...</td>\n",
       "      <td>2021-01-03 15:58:11</td>\n",
       "      <td>3.769691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.767385</td>\n",
       "      <td>-173.924477</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-173.924 -82.767)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>922D_242L</td>\n",
       "      <td>-922</td>\n",
       "      <td>-242</td>\n",
       "      <td>S2B_MSIL2A_20181220T155319_N9999_R025_T01CEJ_2...</td>\n",
       "      <td>2018-12-20 15:53:19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-82.766864</td>\n",
       "      <td>-173.212021</td>\n",
       "      <td>EPSG:32701</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>4</td>\n",
       "      <td>POINT (-173.212 -82.767)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_cell  grid_row_u  grid_col_r  \\\n",
       "0  922D_249L        -922        -249   \n",
       "1  922D_245L        -922        -245   \n",
       "2  922D_244L        -922        -244   \n",
       "3  922D_243L        -922        -243   \n",
       "4  922D_242L        -922        -242   \n",
       "\n",
       "                                          product_id           timestamp  \\\n",
       "0  S2A_MSIL2A_20230119T161811_N0509_R111_T01CDJ_2... 2023-01-19 16:18:11   \n",
       "1  S2B_MSIL2A_20181219T162339_N9999_R011_T01CEJ_2... 2018-12-19 16:23:39   \n",
       "2  S2A_MSIL2A_20200119T155811_N9999_R025_T01CEJ_2... 2020-01-19 15:58:11   \n",
       "3  S2A_MSIL2A_20210103T155811_N9999_R025_T01CEJ_2... 2021-01-03 15:58:11   \n",
       "4  S2B_MSIL2A_20181220T155319_N9999_R025_T01CEJ_2... 2018-12-20 15:53:19   \n",
       "\n",
       "   cloud_cover  nodata  centre_lat  centre_lon         crs  \\\n",
       "0    18.941737     0.0  -82.770666 -178.200331  EPSG:32701   \n",
       "1    22.742201     0.0  -82.768451 -175.349546  EPSG:32701   \n",
       "2     0.000000     0.0  -82.767914 -174.636985  EPSG:32701   \n",
       "3     3.769691     0.0  -82.767385 -173.924477  EPSG:32701   \n",
       "4     0.000000     0.0  -82.766864 -173.212021  EPSG:32701   \n",
       "\n",
       "                                         parquet_url  parquet_row  \\\n",
       "0  https://huggingface.co/datasets/Major-TOM/Core...            0   \n",
       "1  https://huggingface.co/datasets/Major-TOM/Core...            1   \n",
       "2  https://huggingface.co/datasets/Major-TOM/Core...            2   \n",
       "3  https://huggingface.co/datasets/Major-TOM/Core...            3   \n",
       "4  https://huggingface.co/datasets/Major-TOM/Core...            4   \n",
       "\n",
       "                   geometry  \n",
       "0  POINT (-178.200 -82.771)  \n",
       "1  POINT (-175.350 -82.768)  \n",
       "2  POINT (-174.637 -82.768)  \n",
       "3  POINT (-173.924 -82.767)  \n",
       "4  POINT (-173.212 -82.767)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "df = pq.read_table(LOCAL_URL).to_pandas()\n",
    "df['timestamp'] = pd.to_datetime(df.timestamp)\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.centre_lon, df.centre_lat), crs=df.crs.iloc[0]\n",
    ")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c3a158-1bbf-4554-a235-5acc83bd78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metadata(df,\n",
    "                    region=None,\n",
    "                    daterange=None,\n",
    "                    cloud_cover=(0,100),\n",
    "                    nodata=(0, 1.0)\n",
    "                   ):\n",
    "    \"\"\"Filters the Major-TOM dataframe based on several parameters\n",
    "\n",
    "    Args:\n",
    "        df (geopandas dataframe): Parent dataframe\n",
    "        region (shapely geometry object) : Region of interest\n",
    "        daterange (tuple) : Inclusive range of dates (example format: '2020-01-01')\n",
    "        cloud_cover (tuple) : Inclusive percentage range (0-100) of cloud cover\n",
    "        nodata (tuple) : Inclusive fraction (0.0-1.0) of no data allowed in a sample\n",
    "\n",
    "    Returns:\n",
    "        df: a filtered dataframe\n",
    "    \"\"\"\n",
    "    # temporal filtering\n",
    "    if daterange is not None:\n",
    "        assert (isinstance(daterange, list) or isinstance(daterange, tuple)) and len(daterange)==2\n",
    "        df = df[df.timestamp >= daterange[0]]\n",
    "        df = df[df.timestamp <= daterange[1]]\n",
    "    \n",
    "    # spatial filtering\n",
    "    if region is not None:\n",
    "        idxs = df.sindex.query(region)\n",
    "        df = df.take(idxs)\n",
    "    # cloud filtering\n",
    "    if cloud_cover is not None:\n",
    "        df = df[df.cloud_cover >= cloud_cover[0]]\n",
    "        df = df[df.cloud_cover <= cloud_cover[1]]\n",
    "\n",
    "    # spatial filtering\n",
    "    if nodata is not None:\n",
    "        df = df[df.nodata >= nodata[0]]\n",
    "        df = df[df.nodata <= nodata[1]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a0fcff-7df1-466d-9109-b4a64f7daf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "\n",
    "# Example bounding boxes used for filtering\n",
    "switzerland = box(5.9559111595,45.8179931641,10.4920501709,47.808380127)\n",
    "gabon = box(8.1283659854,-4.9213919841,15.1618722208,2.7923006325)\n",
    "napoli = box(14.091710578,40.7915558593,14.3723765416,40.9819258062)\n",
    "pacific = box(-153.3922893485,39.6170415622,-152.0423077748,40.7090892316) # a remote patch over pacific - no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb50b0db-249a-42e7-ac2f-b18ca682a5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = filter_metadata(gdf,\n",
    "                              cloud_cover = (0,10),\n",
    "                              region=switzerland,\n",
    "                              daterange=('2020-01-01', '2025-01-01'),\n",
    "                              nodata=(0.0,0.0)\n",
    "                              )\n",
    "\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72f3406-c23d-4f54-b589-45b6511cb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsspec.parquet import open_parquet_file\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from rasterio.io import MemoryFile\n",
    "\n",
    "def read_row(row, columns=[\"thumbnail\"]):\n",
    "    \"\"\"Reads a row from a Major-TOM dataframe\n",
    "\n",
    "    Args:\n",
    "        row (row from geopandas dataframe): The row of metadata\n",
    "        columns (list): columns to be read from the file\n",
    "\n",
    "    Returns:\n",
    "        data (dict): dictionary with returned data from requested columns\n",
    "    \"\"\"\n",
    "    with open_parquet_file(row.parquet_url,columns = columns) as f:\n",
    "        with pq.ParquetFile(f) as pf:\n",
    "            row_group = pf.read_row_group(row.parquet_row, columns=columns)\n",
    "\n",
    "    if columns == [\"thumbnail\"]:\n",
    "        stream = BytesIO(row_group['thumbnail'][0].as_py())\n",
    "        return Image.open(stream)\n",
    "    else:\n",
    "        row_output = {}\n",
    "        for col in columns:\n",
    "            bytes = row_group[col][0].as_py()\n",
    "\n",
    "            if col != 'thumbnail':\n",
    "                with MemoryFile(bytes) as mem_f:\n",
    "                    with mem_f.open(driver='GTiff') as f:\n",
    "                        row_output[col] = f.read().squeeze()\n",
    "            else:\n",
    "                stream = BytesIO(bytes)\n",
    "                row_output[col] = Image.open(stream)\n",
    "\n",
    "        return row_output\n",
    "        \n",
    "\n",
    "out = read_row(filtered_df.iloc[0], columns = ['B04', 'thumbnail'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044c465-bc91-4d56-89de-7121970f4271",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5547d11b-28c8-4408-9345-3cca4a024f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_cell</th>\n",
       "      <th>grid_row_u</th>\n",
       "      <th>grid_col_r</th>\n",
       "      <th>product_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>nodata</th>\n",
       "      <th>centre_lat</th>\n",
       "      <th>centre_lon</th>\n",
       "      <th>crs</th>\n",
       "      <th>parquet_url</th>\n",
       "      <th>parquet_row</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1697089</th>\n",
       "      <td>510U_80R</td>\n",
       "      <td>510</td>\n",
       "      <td>80</td>\n",
       "      <td>S2B_MSIL2A_20211018T101939_N0500_R065_T32TPR_2...</td>\n",
       "      <td>2021-10-18 10:19:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.852619</td>\n",
       "      <td>10.373241</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>176</td>\n",
       "      <td>POINT (10.373 45.853)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697078</th>\n",
       "      <td>510U_69R</td>\n",
       "      <td>510</td>\n",
       "      <td>69</td>\n",
       "      <td>S2A_MSIL2A_20200521T102031_N0500_R065_T32TMR_2...</td>\n",
       "      <td>2020-05-21 10:20:31</td>\n",
       "      <td>1.069327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.853430</td>\n",
       "      <td>8.954794</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>165</td>\n",
       "      <td>POINT (8.955 45.853)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697077</th>\n",
       "      <td>510U_68R</td>\n",
       "      <td>510</td>\n",
       "      <td>68</td>\n",
       "      <td>S2B_MSIL2A_20211018T101939_N0500_R065_T32TMR_2...</td>\n",
       "      <td>2021-10-18 10:19:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.853502</td>\n",
       "      <td>8.825842</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>164</td>\n",
       "      <td>POINT (8.826 45.854)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697076</th>\n",
       "      <td>510U_67R</td>\n",
       "      <td>510</td>\n",
       "      <td>67</td>\n",
       "      <td>S2A_MSIL2A_20201028T102141_N0500_R065_T32TMR_2...</td>\n",
       "      <td>2020-10-28 10:21:41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.853574</td>\n",
       "      <td>8.696890</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>163</td>\n",
       "      <td>POINT (8.697 45.854)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697074</th>\n",
       "      <td>510U_65R</td>\n",
       "      <td>510</td>\n",
       "      <td>65</td>\n",
       "      <td>S2A_MSIL2A_20201028T102141_N0500_R065_T32TMR_2...</td>\n",
       "      <td>2020-10-28 10:21:41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.853718</td>\n",
       "      <td>8.438985</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>161</td>\n",
       "      <td>POINT (8.439 45.854)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736201</th>\n",
       "      <td>531U_48R</td>\n",
       "      <td>531</td>\n",
       "      <td>48</td>\n",
       "      <td>S2A_MSIL2A_20230820T103631_N0509_R008_T32TLT_2...</td>\n",
       "      <td>2023-08-20 10:36:31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.741042</td>\n",
       "      <td>6.469137</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>290</td>\n",
       "      <td>POINT (6.469 47.741)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736219</th>\n",
       "      <td>531U_66R</td>\n",
       "      <td>531</td>\n",
       "      <td>66</td>\n",
       "      <td>S2A_MSIL2A_20210903T102021_N0301_R065_T32TMT_2...</td>\n",
       "      <td>2021-09-03 10:20:21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.739692</td>\n",
       "      <td>8.873050</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>308</td>\n",
       "      <td>POINT (8.873 47.740)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736218</th>\n",
       "      <td>531U_65R</td>\n",
       "      <td>531</td>\n",
       "      <td>65</td>\n",
       "      <td>S2A_MSIL2A_20200401T102021_N0500_R065_T32TMT_2...</td>\n",
       "      <td>2020-04-01 10:20:21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.739769</td>\n",
       "      <td>8.739502</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>307</td>\n",
       "      <td>POINT (8.740 47.740)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736216</th>\n",
       "      <td>531U_63R</td>\n",
       "      <td>531</td>\n",
       "      <td>63</td>\n",
       "      <td>S2A_MSIL2A_20230625T101601_N0509_R065_T32TMT_2...</td>\n",
       "      <td>2023-06-25 10:16:01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.739922</td>\n",
       "      <td>8.472406</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>305</td>\n",
       "      <td>POINT (8.472 47.740)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736215</th>\n",
       "      <td>531U_62R</td>\n",
       "      <td>531</td>\n",
       "      <td>62</td>\n",
       "      <td>S2B_MSIL2A_20210404T102559_N0500_R108_T32TMT_2...</td>\n",
       "      <td>2021-04-04 10:25:59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.739999</td>\n",
       "      <td>8.338857</td>\n",
       "      <td>EPSG:32632</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>304</td>\n",
       "      <td>POINT (8.339 47.740)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        grid_cell  grid_row_u  grid_col_r  \\\n",
       "1697089  510U_80R         510          80   \n",
       "1697078  510U_69R         510          69   \n",
       "1697077  510U_68R         510          68   \n",
       "1697076  510U_67R         510          67   \n",
       "1697074  510U_65R         510          65   \n",
       "...           ...         ...         ...   \n",
       "1736201  531U_48R         531          48   \n",
       "1736219  531U_66R         531          66   \n",
       "1736218  531U_65R         531          65   \n",
       "1736216  531U_63R         531          63   \n",
       "1736215  531U_62R         531          62   \n",
       "\n",
       "                                                product_id  \\\n",
       "1697089  S2B_MSIL2A_20211018T101939_N0500_R065_T32TPR_2...   \n",
       "1697078  S2A_MSIL2A_20200521T102031_N0500_R065_T32TMR_2...   \n",
       "1697077  S2B_MSIL2A_20211018T101939_N0500_R065_T32TMR_2...   \n",
       "1697076  S2A_MSIL2A_20201028T102141_N0500_R065_T32TMR_2...   \n",
       "1697074  S2A_MSIL2A_20201028T102141_N0500_R065_T32TMR_2...   \n",
       "...                                                    ...   \n",
       "1736201  S2A_MSIL2A_20230820T103631_N0509_R008_T32TLT_2...   \n",
       "1736219  S2A_MSIL2A_20210903T102021_N0301_R065_T32TMT_2...   \n",
       "1736218  S2A_MSIL2A_20200401T102021_N0500_R065_T32TMT_2...   \n",
       "1736216  S2A_MSIL2A_20230625T101601_N0509_R065_T32TMT_2...   \n",
       "1736215  S2B_MSIL2A_20210404T102559_N0500_R108_T32TMT_2...   \n",
       "\n",
       "                  timestamp  cloud_cover  nodata  centre_lat  centre_lon  \\\n",
       "1697089 2021-10-18 10:19:39     0.000000     0.0   45.852619   10.373241   \n",
       "1697078 2020-05-21 10:20:31     1.069327     0.0   45.853430    8.954794   \n",
       "1697077 2021-10-18 10:19:39     0.000000     0.0   45.853502    8.825842   \n",
       "1697076 2020-10-28 10:21:41     0.000000     0.0   45.853574    8.696890   \n",
       "1697074 2020-10-28 10:21:41     0.000000     0.0   45.853718    8.438985   \n",
       "...                     ...          ...     ...         ...         ...   \n",
       "1736201 2023-08-20 10:36:31     0.000000     0.0   47.741042    6.469137   \n",
       "1736219 2021-09-03 10:20:21     0.000000     0.0   47.739692    8.873050   \n",
       "1736218 2020-04-01 10:20:21     0.000000     0.0   47.739769    8.739502   \n",
       "1736216 2023-06-25 10:16:01     0.000000     0.0   47.739922    8.472406   \n",
       "1736215 2021-04-04 10:25:59     0.000000     0.0   47.739999    8.338857   \n",
       "\n",
       "                crs                                        parquet_url  \\\n",
       "1697089  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1697078  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1697077  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1697076  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1697074  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "...             ...                                                ...   \n",
       "1736201  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1736219  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1736218  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1736216  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1736215  EPSG:32632  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "\n",
       "         parquet_row               geometry  \n",
       "1697089          176  POINT (10.373 45.853)  \n",
       "1697078          165   POINT (8.955 45.853)  \n",
       "1697077          164   POINT (8.826 45.854)  \n",
       "1697076          163   POINT (8.697 45.854)  \n",
       "1697074          161   POINT (8.439 45.854)  \n",
       "...              ...                    ...  \n",
       "1736201          290   POINT (6.469 47.741)  \n",
       "1736219          308   POINT (8.873 47.740)  \n",
       "1736218          307   POINT (8.740 47.740)  \n",
       "1736216          305   POINT (8.472 47.740)  \n",
       "1736215          304   POINT (8.339 47.740)  \n",
       "\n",
       "[368 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "864ccdc6-03ae-48cc-a4a5-3c87409e6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import fsspec\n",
    "\n",
    "def download_parquet(df, local_dir, source_name, url, temp_filestub, by_row=False, tif_columns=None):\n",
    "    # Turn for loop of filter_download into parallelizable func\n",
    "\n",
    "    # identify all relevant rows\n",
    "    rows = df[df.parquet_url == url].parquet_row.unique()\n",
    "    \n",
    "    if not by_row: # (downloads entire parquet)        \n",
    "        # download a temporary file\n",
    "        temp_file = temp_filestub+url.split('/')[-1]\n",
    "        temp_path, http_resp = urllib.request.urlretrieve(url, temp_file)            \n",
    "    else:\n",
    "        f=fsspec.open(url)\n",
    "        temp_path = f.open()\n",
    "\n",
    "    # populate the bands\n",
    "    with pq.ParquetFile(temp_path) as pf:\n",
    "        for row_idx in rows:\n",
    "            table = pf.read_row_group(row_idx)\n",
    "\n",
    "            product_id = table['product_id'][0].as_py()\n",
    "            grid_cell = table['grid_cell'][0].as_py()\n",
    "            row = grid_cell.split('_')[0]\n",
    "        \n",
    "            dest = local_dir / Path(\"{}/{}/{}/{}\".format(source_name, row, grid_cell, product_id))\n",
    "            dest.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            columns = [col for col in table.column_names if col[0] == 'B'] + ['cloud_mask'] if tif_columns is None else tif_columns\n",
    "            # tifs\n",
    "            for col in columns:\n",
    "                with open(dest / \"{}.tif\".format(col), \"wb\") as f:\n",
    "                    # Write bytes to file\n",
    "                    f.write(table[col][0].as_py())\n",
    "\n",
    "            # thumbnail (png)\n",
    "            col = 'thumbnail'\n",
    "            with open(dest / \"{}.png\".format(col), \"wb\") as f:\n",
    "                # Write bytes to file\n",
    "                f.write(table[col][0].as_py())\n",
    "    if not by_row:\n",
    "        # remove downloaded file\n",
    "        os.remove(temp_path)\n",
    "    else:\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def filter_download(df, local_dir, source_name, by_row=False, verbose=False, tif_columns=None, num_workers=1):\n",
    "    \"\"\"Downloads and unpacks the data of Major-TOM based on a metadata dataframe\n",
    "\n",
    "    Args:\n",
    "        df (geopandas dataframe): Metadata dataframe\n",
    "        local_dir (str or Path) : Path to the where the data is to be stored locally\n",
    "        source_name (str) : Name alias of the resulting dataset\n",
    "        num_workers (int) : Number of workers for parallel download\n",
    "        by_row (bool): If True, it will access individual rows of parquet via http - otherwise entire parquets are downloaded temporarily\n",
    "        verbose (bool) : option for potential internal state printing\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(local_dir, str):\n",
    "        local_dir = Path(local_dir)\n",
    "\n",
    "    temp_filestub = local_dir / 'temp_'\n",
    "\n",
    "    # identify all parquets that need to be downloaded (group them)\n",
    "    urls = df.parquet_url.unique()\n",
    "    print('Starting download of {} parquet files.'.format(len(urls))) if verbose else None\n",
    "\n",
    "    if num_workers > 1:\n",
    "        from multiprocessing import Pool\n",
    "        pool = Pool(num_workers)\n",
    "        pool.starmap(download_parquet, [(df, local_dir, source_name, url, temp_filestub, by_row, tif_columns) for url in urls])\n",
    "        pool.close()\n",
    "    else:\n",
    "        for url in tqdm(urls, desc='Downloading and unpacking...'):\n",
    "            download_parquet(df, local_dir, source_name, url, temp_filestub, by_row, tif_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335ab665-8238-4f17-ab4b-0bcb1fa38224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03395.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03399.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03402.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03406.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03410.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03413.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03414.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03417.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03421.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03425.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03429.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03432.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03428.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03436.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03440.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03443.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03447.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03451.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03455.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03458.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03462.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03466.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03469.parquet'\n",
      " 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03473.parquet']\n",
      "https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03406.parquet\n",
      "https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/images/part_03395.parquet\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfilter_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/swizz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL2A\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 82\u001b[0m, in \u001b[0;36mfilter_download\u001b[0;34m(df, local_dir, source_name, by_row, verbose, tif_columns, num_workers)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[1;32m     81\u001b[0m     pool \u001b[38;5;241m=\u001b[39m Pool(num_workers)\n\u001b[0;32m---> 82\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_parquet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_filestub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtif_columns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43murls\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     pool\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/vol/miniconda3/envs/torch2/lib/python3.11/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vol/miniconda3/envs/torch2/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/vol/miniconda3/envs/torch2/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vol/miniconda3/envs/torch2/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/vol/miniconda3/envs/torch2/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filter_download(filtered_df, local_dir='./data/swizz', source_name='L2A', by_row=True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c9c0fc63-30ef-48ab-9b2a-ea9bc94441cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88024cc750b041459211e3594703f79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading and unpacking...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_download(filtered_df, local_dir='./data/mczerkawski', source_name='L2A', by_row=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b33084-cc9c-4b4e-acff-e6b68e64ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': grid_cell                                              454U_120R\n",
       " grid_row_u                                                   454\n",
       " grid_col_r                                                   120\n",
       " product_id     S2B_MSIL1C_20220719T095559_N0400_R122_T33TVF_2...\n",
       " timestamp                                    2022-07-19 09:55:59\n",
       " cloud_cover                                                  0.0\n",
       " nodata                                                       0.0\n",
       " centre_lat                                             40.823861\n",
       " centre_lon                                             14.292709\n",
       " crs                                                   EPSG:32633\n",
       " parquet_url    https://huggingface.co/datasets/Major-TOM/Core...\n",
       " parquet_row                                                  455\n",
       " geometry             POINT (14.29270867998482 40.82386055223662)\n",
       " Name: 1593374, dtype: object,\n",
       " 'cloud_mask': array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       " 'thumbnail': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1068x1068>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import rasterio as rio\n",
    "\n",
    "class MajorTOM(Dataset):\n",
    "    \"\"\"MajorTOM Dataset (https://huggingface.co/Major-TOM)\n",
    "\n",
    "    Args:\n",
    "        df ((geo)pandas.DataFrame): Metadata dataframe\n",
    "        local_dir (string): Root directory of the local dataset version\n",
    "        tif_bands (list): A list of tif file names to be read\n",
    "        png_bands (list): A list of png file names to be read\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 local_dir = None,\n",
    "                 tif_bands=['B04','B03','B02'],\n",
    "                 png_bands=['thumbnail']\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.local_dir = Path(local_dir) if isinstance(local_dir,str) else local_dir\n",
    "        self.tif_bands = tif_bands if not isinstance(tif_bands,str) else [tif_bands]\n",
    "        self.png_bands = png_bands if not isinstance(png_bands,str) else [png_bands]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        meta = self.df.iloc[idx]\n",
    "\n",
    "        product_id = meta.product_id\n",
    "        grid_cell = meta.grid_cell\n",
    "        row = grid_cell.split('_')[0]\n",
    "    \n",
    "        path = self.local_dir / Path(\"{}/{}/{}\".format(row, grid_cell, product_id))\n",
    "        out_dict = {'meta' : meta}\n",
    "        \n",
    "        for band in self.tif_bands:\n",
    "            with rio.open(path / '{}.tif'.format(band)) as f:\n",
    "                out = f.read()\n",
    "            out_dict[band] = out\n",
    "\n",
    "        for band in self.png_bands:\n",
    "            out_dict[band] = Image.open(path / '{}.png'.format(band))\n",
    "\n",
    "        return out_dict\n",
    "        \n",
    "ds = MajorTOM(filtered_df, './data/mczerkawski/L2A')\n",
    "\n",
    "ds[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
