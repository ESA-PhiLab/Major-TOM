{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d62a92-c115-4364-90f4-b638c347e493",
   "metadata": {},
   "source": [
    "# Major-TOM Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f518055e-c955-43c6-a5e1-0c05bc657b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATASET_DIR = Path('./data/Major-TOM/')\n",
    "DATASET_DIR.mkdir(exist_ok=True, parents=True)\n",
    "ACCESS_URL = 'https://huggingface.co/datasets/Major-TOM/Core-S2L2A/resolve/main/metadata.parquet?download=true'\n",
    "LOCAL_URL = DATASET_DIR / '{}.parquet'.format(ACCESS_URL.split('.parquet')[0].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bfceaf2e-b877-48a0-a520-450dd73cb57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "LOCAL_URL, RESPONSE = urllib.request.urlretrieve(ACCESS_URL, LOCAL_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a76d787c-4c4d-43da-bc00-adf1067edf63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geopandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mtimestamp)\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m----> 7\u001b[0m gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgeopandas\u001b[49m\u001b[38;5;241m.\u001b[39mGeoDataFrame(\n\u001b[1;32m      8\u001b[0m     df, geometry\u001b[38;5;241m=\u001b[39mgeopandas\u001b[38;5;241m.\u001b[39mpoints_from_xy(df\u001b[38;5;241m.\u001b[39mcentre_lon, df\u001b[38;5;241m.\u001b[39mcentre_lat), crs\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mcrs\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geopandas' is not defined"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "df = pq.read_table(LOCAL_URL).to_pandas()\n",
    "df['timestamp'] = pd.to_datetime(df.timestamp)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdf63818-d42f-44d1-884d-8a7c005b7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.centre_lon, df.centre_lat), crs=df.crs.iloc[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34c3a158-1bbf-4554-a235-5acc83bd78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metadata(df,\n",
    "                    region=None,\n",
    "                    daterange=None,\n",
    "                    cloud_cover=(0,100),\n",
    "                    nodata=(0, 1.0)\n",
    "                   ):\n",
    "    \"\"\"Filters the Major-TOM dataframe based on several parameters\n",
    "\n",
    "    Args:\n",
    "        df (geopandas dataframe): Parent dataframe\n",
    "        region (shapely geometry object) : Region of interest\n",
    "        daterange (tuple) : Inclusive range of dates (example format: '2020-01-01')\n",
    "        cloud_cover (tuple) : Inclusive percentage range (0-100) of cloud cover\n",
    "        nodata (tuple) : Inclusive fraction (0.0-1.0) of no data allowed in a sample\n",
    "\n",
    "    Returns:\n",
    "        df: a filtered dataframe\n",
    "    \"\"\"\n",
    "    # temporal filtering\n",
    "    if daterange is not None:\n",
    "        assert (isinstance(daterange, list) or isinstance(daterange, tuple)) and len(daterange)==2\n",
    "        df = df[df.timestamp >= daterange[0]]\n",
    "        df = df[df.timestamp <= daterange[1]]\n",
    "    \n",
    "    # spatial filtering\n",
    "    if region is not None:\n",
    "        idxs = df.sindex.query(region)\n",
    "        df = df.take(idxs)\n",
    "    # cloud filtering\n",
    "    if cloud_cover is not None:\n",
    "        df = df[df.cloud_cover >= cloud_cover[0]]\n",
    "        df = df[df.cloud_cover <= cloud_cover[1]]\n",
    "\n",
    "    # spatial filtering\n",
    "    if nodata is not None:\n",
    "        df = df[df.nodata >= nodata[0]]\n",
    "        df = df[df.nodata <= nodata[1]]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f8a0fcff-7df1-466d-9109-b4a64f7daf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "\n",
    "switzerland = box(5.9559111595,45.8179931641,10.4920501709,47.808380127)\n",
    "gabon = box(8.1283659854,-4.9213919841,15.1618722208,2.7923006325)\n",
    "napoli = box(14.091710578,40.7915558593,14.3723765416,40.9819258062)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb50b0db-249a-42e7-ac2f-b18ca682a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter_metadata(gdf,\n",
    "                              cloud_cover = (0,10),\n",
    "                              region=napoli,\n",
    "                              daterange=('2020-01-01', '2025-01-01'),\n",
    "                              nodata=(0.0,0.0)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c72f3406-c23d-4f54-b589-45b6511cb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsspec.parquet import open_parquet_file\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from rasterio.io import MemoryFile\n",
    "\n",
    "def read_row(row, columns=[\"thumbnail\"]):\n",
    "    \"\"\"Reads a row from a Major-TOM dataframe\n",
    "\n",
    "    Args:\n",
    "        row (row from geopandas dataframe): The row of metadata\n",
    "        columns (list): columns to be read from the file\n",
    "\n",
    "    Returns:\n",
    "        data (dict): dictionary with returned data from requested columns\n",
    "    \"\"\"\n",
    "    with open_parquet_file(row.parquet_url,columns = columns) as f:\n",
    "        with pq.ParquetFile(f) as pf:\n",
    "            row_group = pf.read_row_group(row.parquet_row, columns=columns)\n",
    "\n",
    "    if columns == [\"thumbnail\"]:\n",
    "        stream = BytesIO(row_group['thumbnail'][0].as_py())\n",
    "        return Image.open(stream)\n",
    "    else:\n",
    "        row_output = {}\n",
    "        for col in columns:\n",
    "            bytes = row_group[col][0].as_py()\n",
    "\n",
    "            if col != 'thumbnail':\n",
    "                with MemoryFile(bytes) as mem_f:\n",
    "                    with mem_f.open(driver='GTiff') as f:\n",
    "                        row_output[col] = f.read().squeeze()\n",
    "            else:\n",
    "                stream = BytesIO(bytes)\n",
    "                row_output[col] = Image.open(stream)\n",
    "\n",
    "        return row_output\n",
    "        \n",
    "\n",
    "out = read_row(filtered_df.iloc[0], columns = ['B04', 'thumbnail'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044c465-bc91-4d56-89de-7121970f4271",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5547d11b-28c8-4408-9345-3cca4a024f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_cell</th>\n",
       "      <th>grid_row_u</th>\n",
       "      <th>grid_col_r</th>\n",
       "      <th>product_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>nodata</th>\n",
       "      <th>centre_lat</th>\n",
       "      <th>centre_lon</th>\n",
       "      <th>crs</th>\n",
       "      <th>parquet_url</th>\n",
       "      <th>parquet_row</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593374</th>\n",
       "      <td>454U_120R</td>\n",
       "      <td>454</td>\n",
       "      <td>120</td>\n",
       "      <td>S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...</td>\n",
       "      <td>2022-07-19 09:55:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.823861</td>\n",
       "      <td>14.292709</td>\n",
       "      <td>EPSG:32633</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>455</td>\n",
       "      <td>POINT (14.293 40.824)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595266</th>\n",
       "      <td>455U_120R</td>\n",
       "      <td>455</td>\n",
       "      <td>120</td>\n",
       "      <td>S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...</td>\n",
       "      <td>2022-07-19 09:55:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.913671</td>\n",
       "      <td>14.311585</td>\n",
       "      <td>EPSG:32633</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>347</td>\n",
       "      <td>POINT (14.312 40.914)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595265</th>\n",
       "      <td>455U_119R</td>\n",
       "      <td>455</td>\n",
       "      <td>119</td>\n",
       "      <td>S2A_MSIL2A_20200113T095351_N0500_R079_T33TVF_2...</td>\n",
       "      <td>2020-01-13 09:53:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.913731</td>\n",
       "      <td>14.192730</td>\n",
       "      <td>EPSG:32633</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>346</td>\n",
       "      <td>POINT (14.193 40.914)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_cell  grid_row_u  grid_col_r  \\\n",
       "1593374  454U_120R         454         120   \n",
       "1595266  455U_120R         455         120   \n",
       "1595265  455U_119R         455         119   \n",
       "\n",
       "                                                product_id  \\\n",
       "1593374  S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...   \n",
       "1595266  S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...   \n",
       "1595265  S2A_MSIL2A_20200113T095351_N0500_R079_T33TVF_2...   \n",
       "\n",
       "                  timestamp  cloud_cover  nodata  centre_lat  centre_lon  \\\n",
       "1593374 2022-07-19 09:55:59          0.0     0.0   40.823861   14.292709   \n",
       "1595266 2022-07-19 09:55:59          0.0     0.0   40.913671   14.311585   \n",
       "1595265 2020-01-13 09:53:51          0.0     0.0   40.913731   14.192730   \n",
       "\n",
       "                crs                                        parquet_url  \\\n",
       "1593374  EPSG:32633  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1595266  EPSG:32633  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1595265  EPSG:32633  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "\n",
       "         parquet_row               geometry  \n",
       "1593374          455  POINT (14.293 40.824)  \n",
       "1595266          347  POINT (14.312 40.914)  \n",
       "1595265          346  POINT (14.193 40.914)  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "864ccdc6-03ae-48cc-a4a5-3c87409e6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from fsspec.parquet import open_parquet_file\n",
    "\n",
    "def filter_download(df, local_dir, source_name, by_row = False, verbose = False):\n",
    "    \"\"\"Downloads and unpacks the data of Major-TOM based on a metadata dataframe\n",
    "\n",
    "    Args:\n",
    "        df (geopandas dataframe): Metadata dataframe\n",
    "        local_dir (str or Path) : Path to the where the data is to be stored locally\n",
    "        source_name (str) : Name alias of the resulting dataset\n",
    "        by_row (bool): If True, it will access individual rows of parquet via http - otherwise entire parquets are downloaded temporarily\n",
    "        verbose (bool) : option for potential internal state printing\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(local_dir, str):\n",
    "        local_dir = Path(local_dir)\n",
    "\n",
    "    temp_file = local_dir / 'temp.parquet'\n",
    "\n",
    "    # identify all parquets that need to be downloaded (group them)\n",
    "    urls = df.parquet_url.unique()\n",
    "    print('Starting download of {} parquet files.'.format(len(urls))) if verbose else None\n",
    "\n",
    "    for url in tqdm(urls, desc='Downloading and unpacking...'):\n",
    "        # identify all relevant rows\n",
    "        rows = df[df.parquet_url == url].parquet_row.unique()\n",
    "        \n",
    "        if not by_row: # (downloads entire parquet)        \n",
    "            # download a temporary file\n",
    "            temp_path, http_resp = urllib.request.urlretrieve(url, temp_file)            \n",
    "        else:\n",
    "            temp_path = open_parquet_file(url)\n",
    "            \n",
    "        # populate the bands\n",
    "        with pq.ParquetFile(temp_path) as pf:\n",
    "            for row_idx in rows:\n",
    "                table = pf.read_row_group(row_idx)\n",
    "\n",
    "                product_id = table['product_id'][0].as_py()\n",
    "                grid_cell = table['grid_cell'][0].as_py()\n",
    "                row = grid_cell.split('_')[0]\n",
    "            \n",
    "                dest = local_dir / Path(\"{}/{}/{}/{}\".format(source_name, row, grid_cell, product_id))\n",
    "                dest.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "                columns = [col for col in table.column_names if col[0] == 'B'] + ['cloud_mask']\n",
    "                \n",
    "                # tifs\n",
    "                for col in columns:\n",
    "                    with open(dest / \"{}.tif\".format(col), \"wb\") as f:\n",
    "                        # Write bytes to file\n",
    "                        f.write(table[col][0].as_py())\n",
    "\n",
    "                # thumbnail (png)\n",
    "                col = 'thumbnail'\n",
    "                with open(dest / \"{}.png\".format(col), \"wb\") as f:\n",
    "                    # Write bytes to file\n",
    "                    f.write(table[col][0].as_py())\n",
    "        if not by_row:\n",
    "            # remove downloaded file\n",
    "            os.remove(temp_path)\n",
    "        else:\n",
    "            temp_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "335ab665-8238-4f17-ab4b-0bcb1fa38224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa461b71f094ea4861595de17823e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading and unpacking...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_download(filtered_df, local_dir='./data/mczerkawski', source_name='L2A', by_row=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c9c0fc63-30ef-48ab-9b2a-ea9bc94441cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88024cc750b041459211e3594703f79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading and unpacking...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_download(filtered_df, local_dir='./data/mczerkawski', source_name='L2A', by_row=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "02397071-daa2-4b06-8900-8f5a2ad04ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_cell</th>\n",
       "      <th>grid_row_u</th>\n",
       "      <th>grid_col_r</th>\n",
       "      <th>product_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>nodata</th>\n",
       "      <th>centre_lat</th>\n",
       "      <th>centre_lon</th>\n",
       "      <th>crs</th>\n",
       "      <th>parquet_url</th>\n",
       "      <th>parquet_row</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593374</th>\n",
       "      <td>454U_120R</td>\n",
       "      <td>454</td>\n",
       "      <td>120</td>\n",
       "      <td>S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...</td>\n",
       "      <td>2022-07-19 09:55:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.823861</td>\n",
       "      <td>14.292709</td>\n",
       "      <td>EPSG:32633</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>455</td>\n",
       "      <td>POINT (14.293 40.824)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595266</th>\n",
       "      <td>455U_120R</td>\n",
       "      <td>455</td>\n",
       "      <td>120</td>\n",
       "      <td>S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...</td>\n",
       "      <td>2022-07-19 09:55:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.913671</td>\n",
       "      <td>14.311585</td>\n",
       "      <td>EPSG:32633</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>347</td>\n",
       "      <td>POINT (14.312 40.914)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595265</th>\n",
       "      <td>455U_119R</td>\n",
       "      <td>455</td>\n",
       "      <td>119</td>\n",
       "      <td>S2A_MSIL2A_20200113T095351_N0500_R079_T33TVF_2...</td>\n",
       "      <td>2020-01-13 09:53:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.913731</td>\n",
       "      <td>14.192730</td>\n",
       "      <td>EPSG:32633</td>\n",
       "      <td>https://huggingface.co/datasets/Major-TOM/Core...</td>\n",
       "      <td>346</td>\n",
       "      <td>POINT (14.193 40.914)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_cell  grid_row_u  grid_col_r  \\\n",
       "1593374  454U_120R         454         120   \n",
       "1595266  455U_120R         455         120   \n",
       "1595265  455U_119R         455         119   \n",
       "\n",
       "                                                product_id  \\\n",
       "1593374  S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...   \n",
       "1595266  S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...   \n",
       "1595265  S2A_MSIL2A_20200113T095351_N0500_R079_T33TVF_2...   \n",
       "\n",
       "                  timestamp  cloud_cover  nodata  centre_lat  centre_lon  \\\n",
       "1593374 2022-07-19 09:55:59          0.0     0.0   40.823861   14.292709   \n",
       "1595266 2022-07-19 09:55:59          0.0     0.0   40.913671   14.311585   \n",
       "1595265 2020-01-13 09:53:51          0.0     0.0   40.913731   14.192730   \n",
       "\n",
       "                crs                                        parquet_url  \\\n",
       "1593374  EPSG:32633  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1595266  EPSG:32633  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "1595265  EPSG:32633  https://huggingface.co/datasets/Major-TOM/Core...   \n",
       "\n",
       "         parquet_row               geometry  \n",
       "1593374          455  POINT (14.293 40.824)  \n",
       "1595266          347  POINT (14.312 40.914)  \n",
       "1595265          346  POINT (14.193 40.914)  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "69b33084-cc9c-4b4e-acff-e6b68e64ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': grid_cell                                              454U_120R\n",
       " grid_row_u                                                   454\n",
       " grid_col_r                                                   120\n",
       " product_id     S2B_MSIL2A_20220719T095559_N0400_R122_T33TVF_2...\n",
       " timestamp                                    2022-07-19 09:55:59\n",
       " cloud_cover                                                  0.0\n",
       " nodata                                                       0.0\n",
       " centre_lat                                             40.823861\n",
       " centre_lon                                             14.292709\n",
       " crs                                                   EPSG:32633\n",
       " parquet_url    https://huggingface.co/datasets/Major-TOM/Core...\n",
       " parquet_row                                                  455\n",
       " geometry             POINT (14.29270867998482 40.82386055223662)\n",
       " Name: 1593374, dtype: object,\n",
       " 'B04': array([[[1563, 1437, 1466, ..., 2152, 2128, 2482],\n",
       "         [1463, 1468, 1722, ..., 2418, 2334, 2214],\n",
       "         [1496, 1677, 1882, ..., 3104, 2832, 2546],\n",
       "         ...,\n",
       "         [2014, 2046, 1900, ..., 1944, 1958, 1924],\n",
       "         [2080, 2104, 1834, ..., 1921, 1974, 1954],\n",
       "         [2102, 2110, 1847, ..., 1927, 1938, 1919]]], dtype=uint16),\n",
       " 'thumbnail': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1068x1068>}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "\n",
    "class MajorTOM(Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 local_dir = None,\n",
    "                 tif_bands=['B04','B03','B02'],\n",
    "                 png_bands=['thumbnail']\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.local_dir = Path(local_dir) if isinstance(local_dir,str) else local_dir\n",
    "        self.tif_bands = tif_bands\n",
    "        self.png_bands = png_bands\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        meta = self.df.iloc[idx]\n",
    "\n",
    "        product_id = meta.product_id\n",
    "        grid_cell = meta.grid_cell\n",
    "        row = grid_cell.split('_')[0]\n",
    "    \n",
    "        path = self.local_dir / Path(\"{}/{}/{}\".format(row, grid_cell, product_id))\n",
    "        out_dict = {'meta' : meta}\n",
    "        \n",
    "        for band in self.tif_bands:\n",
    "            with rio.open(path / '{}.tif'.format(band)) as f:\n",
    "                out = f.read()\n",
    "            out_dict[band] = out\n",
    "\n",
    "        for band in self.png_bands:\n",
    "            out_dict[band] = Image.open(path / '{}.png'.format(band))\n",
    "\n",
    "        return out_dict\n",
    "        \n",
    "ds = MajorTOM(filtered_df, './data/mczerkawski/L2A')\n",
    "\n",
    "ds[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miko-torch] *",
   "language": "python",
   "name": "conda-env-miko-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
