{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a703ab93-62b6-41a4-a65c-523975ca319a",
   "metadata": {},
   "source": [
    "Note: steps (1)-(3) only need to be executed **once**\n",
    "\n",
    "If you've already computed your index files and have them stored locally, you can skip to (4)\n",
    "\n",
    "*Want to see this in action? Our viewer app is based on outputs from this exact notebook!* https://huggingface.co/spaces/Major-TOM/MajorTOM-Core-Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "358d18a7-b6a8-4a86-a07e-776cf3307e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import gc\n",
    "import json\n",
    "\n",
    "def get_parquet_files(directory):\n",
    "    return sorted([\n",
    "        os.path.join(directory, f) \n",
    "        for f in os.listdir(directory) \n",
    "        if f.endswith('.parquet')\n",
    "    ])\n",
    "\n",
    "def read_vectors_from_parquet(filepath):\n",
    "    \"\"\"\n",
    "    Reads parquet, extracts 'embedding' column, converts to float32 matrix.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(filepath, columns=['embedding'])\n",
    "    \n",
    "    # The crucial step: Convert column of numpy arrays to a single 2D matrix\n",
    "    # This creates a copy in memory, so we must be careful.\n",
    "    vector_matrix = np.stack(df['embedding'].values)\n",
    "    \n",
    "    # FAISS requires float32 and C-contiguous memory\n",
    "    vector_matrix = np.ascontiguousarray(vector_matrix.astype('float32'))\n",
    "    \n",
    "    # Normalize if you want Cosine Similarity!\n",
    "    faiss.normalize_L2(vector_matrix)\n",
    "    \n",
    "    return vector_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90cc5478-c18e-487b-82b5-8c4576344023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "BASE_DIR='data/Major-TOM/Core-S2RGB-SigLIP'\n",
    "DATA_DIR = f'{BASE_DIR}/embeddings/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18aa95-a4f1-4369-84e3-8e7c06daffc9",
   "metadata": {},
   "source": [
    "# 1. Train FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e931d05-3a55-4691-bbb0-b88d2e5a3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    " # ==========================================\n",
    "# STEP 1: TRAIN THE INDEX\n",
    "# ==========================================\n",
    "print(\"--- STEP 1: TRAINING ---\")\n",
    "files = get_parquet_files(DATA_DIR)\n",
    "train_vectors = []\n",
    "target_train_size = 1500_000 # 500k is usually sufficient for 20M\n",
    "current_count = 0\n",
    "\n",
    "for f in files:\n",
    "    print(f\"Loading {f} for training sample...\")\n",
    "    vecs = read_vectors_from_parquet(f)\n",
    "    \n",
    "    # Take a random subsample from this file to ensure distribution\n",
    "    # (Optional: just take the first N, but random is safer)\n",
    "    indices = np.random.choice(vecs.shape[0], size=min(30000, vecs.shape[0]), replace=False)\n",
    "    sample = vecs[indices]\n",
    "    \n",
    "    train_vectors.append(sample)\n",
    "    current_count += len(sample)\n",
    "    \n",
    "    if current_count >= target_train_size:\n",
    "        break\n",
    "\n",
    "del train_vectors\n",
    "\n",
    "# Stack all training samples\n",
    "train_matrix = np.vstack(train_vectors)\n",
    "print(f\"Training set shape: {train_matrix.shape}\")\n",
    "np.save(f'{BASE_DIR}/train_matrix.npy', train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc73ea-b7e1-4779-9f46-3ca205a6f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix=np.load(f'{BASE_DIR}/train_matrix.npy')\n",
    "\n",
    "# FAISS Hyperparameters\n",
    "D = 1152\n",
    "# 4 * sqrt(N) is a good rule of thumb for nlist. sqrt(20M) ~ 4500. \n",
    "# 16384 or 32768 are good standard powers of 2 for 20M vectors.\n",
    "NLIST = 32768\n",
    "# m must be a divisor of 1152. \n",
    "# m=72 gives 16-dim subvectors (1152/72). Good balance.\n",
    "M = 32         \n",
    "NBITS = 8     \n",
    "\n",
    "# Create the config object\n",
    "cloner_options = faiss.GpuClonerOptions()\n",
    "cloner_options.useFloat16LookupTables = True\n",
    "\n",
    "# Create the index\n",
    "quantizer = faiss.IndexFlatL2(D)\n",
    "index = faiss.IndexIVFPQ(quantizer, D, NLIST, M, NBITS)\n",
    "\n",
    "# Train (Use GPU for training if available to speed it up)\n",
    "# Note: We train on GPU, but we might build on CPU to save VRAM \n",
    "# if the GPU can't hold the growing index + batch data.\n",
    "res = faiss.StandardGpuResources()\n",
    "gpu_index = faiss.index_cpu_to_gpu(res, 0, index, cloner_options)\n",
    "\n",
    "print(\"Training index (this may take a few minutes)...\")\n",
    "gpu_index.train(train_matrix)\n",
    "\n",
    "# Move back to CPU to populate data (Safe method for large RAM)\n",
    "index = faiss.index_gpu_to_cpu(gpu_index)\n",
    "\n",
    "# Clean up memory\n",
    "del train_matrix, gpu_index\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f769a4-3726-4cef-be58-99ad5f84a536",
   "metadata": {},
   "source": [
    "# 2. Encode All Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b7324-4215-4e04-9d49-9c07b8edf612",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STEP 2: INDEXING & METADATA ---\")\n",
    "\n",
    "metadata_chunks = [] # We will store small dataframes here\n",
    "total_vectors = 0\n",
    "\n",
    "files = sorted([os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith('.parquet')])\n",
    "\n",
    "for f_path in files:\n",
    "    f_name = os.path.basename(f_path)\n",
    "    print(f\"Processing {f_name}...\")\n",
    "    \n",
    "    # 1. Read Parquet (Vectors + Grid Cell)\n",
    "    df = gpd.read_parquet(f_path, columns=['embedding', 'grid_cell','geometry'])\n",
    "    \n",
    "    # 2. Process Vectors for FAISS\n",
    "    # Stack vectors into matrix\n",
    "    vecs = np.stack(df['embedding'].values)\n",
    "    vecs = np.ascontiguousarray(vecs.astype('float32'))\n",
    "    faiss.normalize_L2(vecs)\n",
    "    \n",
    "    # 3. Add to FAISS Index\n",
    "    index.add(vecs)\n",
    "    \n",
    "    # 4. Prepare Metadata Chunk\n",
    "    # We only keep necessary columns to save RAM. \n",
    "    # We add 'row_in_file' so you can find the exact original vector later.\n",
    "    meta_chunk = df[['grid_cell','geometry']].copy()\n",
    "    meta_chunk['file'] = f_name\n",
    "    meta_chunk['row_idx'] = np.arange(len(df), dtype=np.int32)\n",
    "    \n",
    "    # Add global FAISS ID (optional, but good for debugging)\n",
    "    # meta_chunk['faiss_id'] = np.arange(total_vectors, total_vectors + len(df), dtype=np.int32)\n",
    "\n",
    "    metadata_chunks.append(meta_chunk)\n",
    "    \n",
    "    total_vectors += len(df)\n",
    "    \n",
    "    # Clean up\n",
    "    del df, vecs, meta_chunk\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"Total vectors indexed: {total_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39874a70-7c85-433d-87d2-2edce43e51c8",
   "metadata": {},
   "source": [
    "# 3. Create Index Mapping (grid_cell to index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae9c88-32e6-4bd2-a971-a189613de677",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_OUTPUT = f'{BASE_DIR}/siglip_ivfpq.index'\n",
    "METADATA_OUTPUT = f'{BASE_DIR}/siglip_ivfpq_metadata.parquet'\n",
    "\n",
    "# --- STEP 3: SAVING ---\n",
    "print(\"\\n--- STEP 3: SAVING ---\")\n",
    "\n",
    "# Save FAISS Index\n",
    "print(f\"Writing index to {INDEX_OUTPUT}...\")\n",
    "faiss.write_index(index, INDEX_OUTPUT)\n",
    "\n",
    "# Save Metadata\n",
    "print(f\"Concatenating and saving metadata to {METADATA_OUTPUT}...\")\n",
    "# This combines all chunks into one table. \n",
    "# Row 0 of this table corresponds to FAISS ID 0.\n",
    "full_metadata =  gpd.GeoDataFrame(pd.concat(metadata_chunks, axis=0, ignore_index=True))\n",
    "\n",
    "# Save as parquet (efficient compression for repeated filenames/grid_cells)\n",
    "full_metadata.to_parquet(METADATA_OUTPUT, index=False)\n",
    "\n",
    "print(\"Done! Metadata shape:\", full_metadata.shape)\n",
    "del full_metadata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80861569-294a-460b-a399-1c5e8ca58568",
   "metadata": {},
   "source": [
    "# 4. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0b1a6b-a822-47be-81c6-bdbba5a01bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def search_with_grid_id(query_vec, k=5):\n",
    "    # Prepare query\n",
    "    if isinstance(query_vec, torch.Tensor):\n",
    "        query_vec = query_vec.cpu().numpy()\n",
    "    query_vec = query_vec.reshape(1, -1).astype('float32')\n",
    "    faiss.normalize_L2(query_vec)\n",
    "    \n",
    "    # Search\n",
    "    distances, indices = gpu_index.search(query_vec, k)\n",
    "    \n",
    "    # Flatten results\n",
    "    ids = indices[0]\n",
    "    scores = distances[0]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Batch lookup in pandas (Faster than looping)\n",
    "    # We ignore -1 (which happens if k > total vectors, unlikely here)\n",
    "    valid_mask = ids != -1\n",
    "    valid_ids = ids[valid_mask]\n",
    "    valid_scores = scores[valid_mask]\n",
    "    \n",
    "    if len(valid_ids) > 0:\n",
    "        # MAGIC LINE: Direct lookup by integer index\n",
    "        matches = metadata_df.iloc[valid_ids].copy()\n",
    "        matches['score'] = valid_scores\n",
    "        \n",
    "        # Convert to list of dicts for easy usage\n",
    "        results = matches.to_dict(orient='records')\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c7f60a-5113-4cc1-a4b6-93b1d859f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miko/miniconda3/envs/miko-torch/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from PATH=data/Major-TOM/Core-S2RGB-SigLIP/siglip_ivfpq.index\n",
      "[DONE]\n",
      "Loading metadata from PATH=data/Major-TOM/Core-S2RGB-SigLIP/siglip_ivfpq_metadata.parquet\n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "from open_clip import create_model_from_pretrained, get_tokenizer\n",
    "\n",
    "class SearchSigLIP():\n",
    "\n",
    "    def __init__(self, index_path, metadata_path):\n",
    "\n",
    "        # 1. Initialise Index\n",
    "        print(f'Loading index from PATH={index_path}')\n",
    "        self.index_path = index_path\n",
    "        self.init_index()\n",
    "        print('[DONE]')\n",
    "\n",
    "        # 2. Initialise Metadata\n",
    "        print(f'Loading metadata from PATH={metadata_path}')\n",
    "        self.metadata_path = metadata_path\n",
    "        self.metadata_df = pd.read_parquet(self.metadata_path)\n",
    "        print('[DONE]')\n",
    "\n",
    "        # 3. Initialise Text Encoder\n",
    "        self.init_model()\n",
    "\n",
    "    def init_index(self):\n",
    "        self.cpu_index = faiss.read_index(self.index_path)\n",
    "        res = faiss.StandardGpuResources()\n",
    "        cloner_options = faiss.GpuClonerOptions()\n",
    "        cloner_options.useFloat16LookupTables = True \n",
    "        self.gpu_index = faiss.index_cpu_to_gpu(res, 0, self.cpu_index, cloner_options)\n",
    "        self.gpu_index.nprobe = 32 # Higher = more accurate, slower\n",
    "\n",
    "    def init_model(self):\n",
    "        self.model, self.preprocess = create_model_from_pretrained('hf-hub:timm/ViT-SO400M-14-SigLIP-384')\n",
    "        self.model.eval()\n",
    "        self.tokenizer = get_tokenizer('hf-hub:timm/ViT-SO400M-14-SigLIP')\n",
    "\n",
    "    def encode_text(self, text, device='cuda'):\n",
    "        self.model.to(device)\n",
    "        with torch.no_grad():\n",
    "            text = self.tokenizer([text], context_length=self.model.context_length)\n",
    "            return self.model.encode_text(text.to(device))\n",
    "\n",
    "    def search_with_grid(self, query_vec, k=5):\n",
    "        # Prepare query\n",
    "        if isinstance(query_vec, torch.Tensor):\n",
    "            query_vec = query_vec.cpu().squeeze().numpy()\n",
    "            \n",
    "        query_vec = query_vec.reshape(1, -1).astype('float32')\n",
    "        faiss.normalize_L2(query_vec)\n",
    "        \n",
    "        # Search\n",
    "        distances, indices = self.gpu_index.search(query_vec, k)\n",
    "        \n",
    "        # Flatten results\n",
    "        ids = indices[0]\n",
    "        scores = distances[0]\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Batch lookup in pandas (Faster than looping)\n",
    "        # We ignore -1 (which happens if k > total vectors, unlikely here)\n",
    "        valid_mask = ids != -1\n",
    "        valid_ids = ids[valid_mask]\n",
    "        valid_scores = scores[valid_mask]\n",
    "        \n",
    "        if len(valid_ids) > 0:\n",
    "            # MAGIC LINE: Direct lookup by integer index\n",
    "            matches = self.metadata_df.iloc[valid_ids].copy()\n",
    "            matches['score'] = valid_scores\n",
    "            \n",
    "            # Convert to list of dicts for easy usage\n",
    "            results = matches.to_dict(orient='records')\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def faiss(self, text, k=1): # k - number of neighbours\n",
    "\n",
    "        # 1. Compute query\n",
    "        q = self.encode_text(text)\n",
    "\n",
    "        # 2. Find Hits\n",
    "        results = self.search_with_grid(q, k=k)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "BASE_DIR='data/Major-TOM/Core-S2RGB-SigLIP'\n",
    "INDEX_OUTPUT = f'{BASE_DIR}/siglip_ivfpq.index'\n",
    "METADATA_OUTPUT = f'{BASE_DIR}/siglip_ivfpq_metadata.parquet'\n",
    "\n",
    "search = SearchSigLIP(index_path=INDEX_OUTPUT,\n",
    "                      metadata_path=METADATA_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5994c27c-087b-4c58-b1de-07ab0ed2f649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'grid_cell': '573U_2L',\n",
       "  'geometry': b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00S>\\xa8\\x98\\x99\\xec\\xc7\\xbf\\x81/\\xaf\\xfa\\x81\\xbfI@h$\\xcc\\xca%2\\xc8\\xbf]\\xa6\\xef\\xea\\x17\\xbbI@\\x1c\\x8b6SHC\\xcf\\xbfY\\x9c\\xac\\xe4B\\xbbI@\\xdb\\xb7&\\xbb\\x18\\xff\\xce\\xbfa:\\xef\\x01\\xad\\xbfI@S>\\xa8\\x98\\x99\\xec\\xc7\\xbf\\x81/\\xaf\\xfa\\x81\\xbfI@',\n",
       "  'file': 'part_03601-03700.parquet',\n",
       "  'row_idx': 114071,\n",
       "  'score': 1.7111053466796875},\n",
       " {'grid_cell': '594U_19L',\n",
       "  'geometry': b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00b\\x07\\xca\\xd7\\xc4s\\x06\\xc0er\\xa9\\xe5\\x1b\\xb9J@\\x19 L\\xfb\\x16t\\x06\\xc0Hpv\\xda\\xb0\\xb4J@\\xe8\\xd8c\\x12g\\xea\\x06\\xc0\\x990\\xadu\\xb3\\xb4J@{j\\xa2z-\\xea\\x06\\xc0\\x14\\x0c\\xb6\\x81\\x1e\\xb9J@b\\x07\\xca\\xd7\\xc4s\\x06\\xc0er\\xa9\\xe5\\x1b\\xb9J@',\n",
       "  'file': 'part_03701-03800.parquet',\n",
       "  'row_idx': 12447,\n",
       "  'score': 1.7131608724594116},\n",
       " {'grid_cell': '565U_2L',\n",
       "  'geometry': b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x9d\\xea\\x80\\xf9\\x83K\\xcd\\xbf\\x91\\xf8\\xf2&\\x8ckI@\\xff2\\x95\\\\q\\x8e\\xcd\\xbfSgC\\xec!gI@\\x8f\\x15X\\x04\\x18C\\xd2\\xbf\\x95-\\xcc\\xdfKgI@+\\\\O8I\"\\xd2\\xbf\\\\\\xd6\\x9b\\'\\xb6kI@\\x9d\\xea\\x80\\xf9\\x83K\\xcd\\xbf\\x91\\xf8\\xf2&\\x8ckI@',\n",
       "  'file': 'part_03501-03600.parquet',\n",
       "  'row_idx': 433818,\n",
       "  'score': 1.7177265882492065},\n",
       " {'grid_cell': '333U_87L',\n",
       "  'geometry': b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00j\\'\\xdbQd\\xf5!\\xc0\\x98L\\xe6\\x89\\x17\\xf1=@\\xed\\x16\\xa1Be\\xf5!\\xc0\\x85U\"e8\\xe8=@\\x07\\xdc\\x94\\xf4\\xc2\\t\"\\xc0\\x0e\\x84Li8\\xe8=@Jn7\\xd2\\xc3\\t\"\\xc0T\\xf7\\x11\\x8e\\x17\\xf1=@j\\'\\xdbQd\\xf5!\\xc0\\x98L\\xe6\\x89\\x17\\xf1=@',\n",
       "  'file': 'part_02701-02800.parquet',\n",
       "  'row_idx': 89795,\n",
       "  'score': 1.7193355560302734},\n",
       " {'grid_cell': '635U_60R',\n",
       "  'geometry': b\"\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00D\\xf2\\x1c\\xa1K'$@?\\xc0ipP\\x90L@\\xcf\\xab\\xea\\x8f\\xc8&$@I\\xee2F\\xe6\\x8bL@\\x85-q\\xd3W\\x06$@\\xe1m\\x04\\x91\\xf7\\x8bL@-s@-\\xd3\\x06$@\\xc8\\xef\\x0b\\xc1a\\x90L@D\\xf2\\x1c\\xa1K'$@?\\xc0ipP\\x90L@\",\n",
       "  'file': 'part_03801-03900.parquet',\n",
       "  'row_idx': 240414,\n",
       "  'score': 1.7228704690933228},\n",
       " {'grid_cell': '573U_2L',\n",
       "  'geometry': b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00c\\x19\\xc8\\x85\\x1aa\\xc1\\xbf\\x08c\\xceYI\\xc3I@\\xb8\\x0e\\xad6\\xfd\\xa7\\xc1\\xbf\\xf1bSX\\xdf\\xbeI@UyC\\xac6\\xba\\xc8\\xbf\\xd5\\x0fS \\x0b\\xbfI@\\x08\\xbd\\xd4\\x1d\\xb1t\\xc8\\xbf\\xee\\xab\\x92/u\\xc3I@c\\x19\\xc8\\x85\\x1aa\\xc1\\xbf\\x08c\\xceYI\\xc3I@',\n",
       "  'file': 'part_03601-03700.parquet',\n",
       "  'row_idx': 114073,\n",
       "  'score': 1.7284319400787354},\n",
       " {'grid_cell': '422U_304R',\n",
       "  'geometry': b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x0b\\xb5_u\"\\\\A@Sq\\xfb\\xa6r\\xffB@\\x9d\\x8d\\x1c\\x01\\x08\\\\A@Lv\"\\x13\\x05\\xfbB@\\xc1\\x0e$5pVA@3\\x88T\\xbc\\x19\\xfbB@\\x00fu\\xfd\\x89VA@$^\\xb9V\\x87\\xffB@\\x0b\\xb5_u\"\\\\A@Sq\\xfb\\xa6r\\xffB@',\n",
       "  'file': 'part_03001-03100.parquet',\n",
       "  'row_idx': 283965,\n",
       "  'score': 1.7287839651107788},\n",
       " {'grid_cell': '602U_2L',\n",
       "  'geometry': b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00X\\xa2\\xdbZ\\xcb\\xb4\\xc2\\xbfUE1\\xd0\\xc0\\x0cK@\\xe4F\\x92LQ\\x02\\xc3\\xbf\\x97T(JW\\x08K@kA\\xccq\\x9f\\x82\\xca\\xbff\\x99:`\\x84\\x08K@\\x93\\x1aw\\x0f\\xb06\\xca\\xbfz\\x11\\xcd\\xf4\\xed\\x0cK@X\\xa2\\xdbZ\\xcb\\xb4\\xc2\\xbfUE1\\xd0\\xc0\\x0cK@',\n",
       "  'file': 'part_03701-03800.parquet',\n",
       "  'row_idx': 148283,\n",
       "  'score': 1.7301812171936035},\n",
       " {'grid_cell': '594U_42L',\n",
       "  'geometry': b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\xdb\\xbc;\\x8d\\xa9\\xa5\\x18\\xc0:\\xdd\\x03\\xf8\\xb6\\xb4J@\\x08m%\\n\\x03\\xa8\\x18\\xc0\\xa3\\x86\\xb0LM\\xb0J@\\x16\\x1f\\xb1\\x08\\r\\xe3\\x18\\xc0\\xcbv\\xb0\\xc1y\\xb0J@\\x8a\\xc8S\\xbc\\xbf\\xe0\\x18\\xc0\\xca\\xde={\\xe3\\xb4J@\\xdb\\xbc;\\x8d\\xa9\\xa5\\x18\\xc0:\\xdd\\x03\\xf8\\xb6\\xb4J@',\n",
       "  'file': 'part_03701-03800.parquet',\n",
       "  'row_idx': 12247,\n",
       "  'score': 1.7303814888000488},\n",
       " {'grid_cell': '628U_18L',\n",
       "  'geometry': b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00\\x00\\x00b\\xe3D\\xa8\\xba\\xea\\x06\\xc0kr\\xecH\\x12<L@1\\xbc\\xaa\\xf3\\xfa\\xea\\x06\\xc0\\xecj\\xb2\\xcd\\xa77L@q\\xb6{\\xf1\\x82j\\x07\\xc0 l\\xf4\\x83\\xa97L@\\xea>t?`j\\x07\\xc0\\x81b\\xc0\\xff\\x13<L@b\\xe3D\\xa8\\xba\\xea\\x06\\xc0kr\\xecH\\x12<L@',\n",
       "  'file': 'part_03801-03900.parquet',\n",
       "  'row_idx': 127153,\n",
       "  'score': 1.7311372756958008}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.faiss(\"London\", k = 10) # k controls the number of nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200dfa1-465a-4f82-8936-f4ebef653d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miko-torch] *",
   "language": "python",
   "name": "conda-env-miko-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
